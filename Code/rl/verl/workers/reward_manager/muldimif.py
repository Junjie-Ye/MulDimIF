# Copyright 2024 Bytedance Ltd. and/or its affiliates
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from verl import DataProto
from verl.utils.reward_score import _default_compute_score
import torch
import sys
import os
from evaluation import check, map_constraint, get_score  # 导入主评估函数
from pprint import pprint



def reward_func(prompt: str, response: str, constraints: list, idx: str, split: str, model_type: str) -> float:
    """Reward function using code to verify"""
    
    if model_type == "qwen":    
        # qwen eos token
        response = response.strip().rstrip('<|endoftext|>').strip().rstrip('<|im_end|>').strip()
    elif model_type == "llama":
        # llama eos token
        response = response.strip().rstrip('<|end_of_text|>').strip().rstrip('<|eot_id|>').strip()
    elif model_type == "deepseek":
        response = response.strip().rstrip('<｜end▁of▁sentence｜>').strip()
        if '</think>' in response:
            response = response.split('</think>')[1]
    else:
        raise ValueError(f"model_type {model_type} not supported")
    data = []
    data.append({
        "id": idx,
        "conversations": [
            {"role": "user", "content": prompt},
            {"role": "assistant", "content": response}
        ],
        "constraints": constraints,
    })
    judge = check(data)[0]['judges']
    if len(judge) == 0:
        return 0.0
    if split == "train":
        return judge.count(1)*1.0
    else:
        return 1.0 if all(x == 1 for x in judge) else 0.0
        

class MulDimIfRewardManager:
    """The reward manager.
    """

    def __init__(self, tokenizer, num_examine, compute_score=None, model_type=None) -> None:
        # for prompt/response decoding
        self.tokenizer = tokenizer
        # control the number of batches of decoded responses to print to the console
        self.num_examine = num_examine  # the number of batches of decoded responses to print to the console
        self.compute_score = compute_score or _default_compute_score
        self.model_type = model_type

    def __call__(self, data: DataProto):
        """We will expand this function gradually based on the available datasets"""

        # If there is rm score, we directly return rm score. Otherwise, we compute via rm_score_fn
        if 'rm_scores' in data.batch.keys():
            return data.batch['rm_scores']

        reward_tensor = torch.zeros_like(data.batch['responses'], dtype=torch.float32)

        already_print_data_sources = {}

        for i in range(len(data)):
            data_item = data[i]  # DataProtoItem

            prompt_ids = data_item.batch['prompts']

            prompt_length = prompt_ids.shape[-1]

            valid_prompt_length = data_item.batch['attention_mask'][:prompt_length].sum()
            valid_prompt_ids = prompt_ids[-valid_prompt_length:]

            response_ids = data_item.batch['responses']
            valid_response_length = data_item.batch['attention_mask'][prompt_length:].sum()
            valid_response_ids = response_ids[:valid_response_length]

            # decode
            prompt_str = self.tokenizer.decode(valid_prompt_ids)
            response_str = self.tokenizer.decode(valid_response_ids)
            
            idx = data_item.non_tensor_batch['idx']
            constraints = data_item.non_tensor_batch['constraints']
            data_source = data_item.non_tensor_batch['data_source']
            split = data_item.non_tensor_batch['split']
            extra_info = data_item.non_tensor_batch.get('extra_info', None)

            score = reward_func(prompt_str, response_str, constraints, idx, split, self.model_type)
            
            reward_tensor[i, valid_response_length - 1] = score

            if data_source not in already_print_data_sources:
                already_print_data_sources[data_source] = 0

            if already_print_data_sources[data_source] < self.num_examine:
                already_print_data_sources[data_source] += 1
                print("[prompt]", prompt_str)
                print("[response]", response_str)
                # print("[constraints]]", constraints)
                print("[score]", score)

        return reward_tensor

if __name__ == "__main__":    
    idx="6b57b8f52aa615482994d893b2c46464-4"
    prompt="What is the purpose of the XML report generated by the sqlpackage deployreport action? Please describe its contents. \nThe output must follow the following rules: \n    1. Each XML element must have no more than three attributes. \n    2. The list of contents should not exceed five rows. \n    3. The response must contain no more than 150 words. \n    4. The response must use capitalized letters for each word. \n    5. Must include the keyword 'sqlpackage'."
    response="Okay, so the user is asking about the purpose of the XML report generated by the sqlpackage deployreport action. They want a description of its contents, with each XML element having no more than three attributes and the response not exceeding five rows. Also, the response needs to be in capitalized letters and under 150 words.\n\nFirst, I need to understand what the deployreport action does. It's part of the SQLPackage deploy tool, so it's used after deploying a SQL package to generate a report. The XML report is likely to document the deployment process, including details about the package, deployment steps, and any issues encountered.\n\nThe user specified that each XML element can have up to three attributes. So, I should structure the XML elements accordingly. Maybe start with a root element like <DEPLOYMENT_REPORT> to encapsulate everything. Then, include elements like <PACKAGE> for the package name, <DEPLOYMENT_STATUS> to show if it succeeded, <DEPLOYMENT_DATE> for when it was done, and <DEPLOYMENT NOTES> to list any issues.\n\nI should make sure each element doesn't have more than three attributes. For example, <PACKAGE> can have NAME, VERSION, and DESCRIPTION. <DEPLOYMENT_STATUS> can have SUCCESSFUL, DATE, and STATUS. The <DEPLOYMENT_NOTES> can have ISSUES, DETAILS, and RECOMMENDATIONS.\n\nI also need to keep the response concise, with no more than five rows. So, I'll list each element and their attributes, ensuring clarity and brevity. The response should be in capitalized letters, so I'll write each word in uppercase.\n\nPutting it all together, the XML report will have a root element with the package details, deployment status, date, and notes. Each element will have up to three attributes, and the entire response will be within 150 words and five rows. This should meet the user's requirements and provide a clear understanding of the report's structure and purpose.\n</think>\n\nTHE XML REPORT GENERATED BY THE SQLPACKAGE DEPLOYREporte ACTION SERVES TO DOCUMENT THE DEPLOYMENT PROCESS OF A SQL PACKAGE. IT CONTAINS DETAILS ABOUT THE DEPLOYMENT, INCLUDING SUCCESSFUL OR ISSUES FACED, THE PACKAGES DEPLOYED, AND ANY NOTES OR RECOMMENDATIONS. THE REPORT IS STRUCTURED WITH ELEMENTS LIKE <DEPLOYMENT_REPORT>, <PACKAGE>, <DEPLOYMENT_STATUS>, <DEPLOYMENT_DATE>, AND <DEPLOYMENT_NOTES>. EACH ELEMENT HAS UP TO THREE ATTRIBUTES, SUCH AS NAME, VERSION, SUCCESSFUL, DATE, STATUS, ISSUES, DETAILS, AND RECOMMENDATIONS. THIS SUMMARY PROVIDES A BRIEF OVERVIEW OF THE DEPLOYMENT OUTCOME AND RELATED INFORMATION."
    constraints= [
        [
            "XML",
            "Number of attributes",
            "Each XML element must have no more than three attributes"
        ],
        [
            "Table",
            "Row limit",
            "The list of contents should not exceed five rows"
        ],
        [
            "Length",
            "Words",
            "The response must contain no more than 150 words"
        ],
        [
            "Language",
            "English",
            "The response must use capitalized letters for each word"
        ],
        [
            "Content",
            "Keywords: Must include",
            "Must include the keyword 'sqlpackage'"
        ]
    ]
    print(reward_func(prompt, response, constraints, idx, split="train", model_type="deepseek_qwen"))
    